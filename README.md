# ğŸš€ Proyecto Big Data Colombia ğŸ‡¨ğŸ‡´

Procesamiento **Batch** y **Streaming en Tiempo Real** usando **PySpark**, **Hadoop** y **Kafka**.  
Este proyecto permite limpiar, transformar y analizar datos sobre beneficios sociales en Colombia, tanto en modo batch (por lotes) como en tiempo real con Kafka.

## ğŸ—‚ï¸ Estructura del Proyecto

```
bigdata_colombia_project/
â”œâ”€â”€ batch_processor.py
â”œâ”€â”€ producer.py
â”œâ”€â”€ stream_processor.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Requisitos Previos

Instala las librerÃ­as necesarias en Python:

```bash
pip install pyspark kafka-python
```
## Inicio de Servicios de Hadoop (HDFS y YARN)
Antes de ejecutar cualquier comando de Spark/HDFS, verifica que los servicios estÃ©n activos
Inicia con el usuario donde tengas hadoop instalado. 
# 1. Iniciar el sistema de archivos distribuido (HDFS)
start-dfs.sh
# 2. Iniciar el gestor de recursos (YARN)
start-yarn.sh
# 3. Verificar que los procesos estÃ©n corriendo (debes ver NameNode, DataNode, ResourceManager, NodeManager)

## Descarga y Carga del Dataset a HDFS
Descarga el archivo CSV y cÃ¡rgalo al directorio de HDFS que usarÃ¡ el script.
Descargar el archivo (ejecutar en tu mÃ¡quina local o VM):
wget -O datos_colombia.csv https://www.datos.gov.co/api/views/xfif-myr2/rows.csv?accessType=DOWNLOAD

## crear un script PySpark (batch_processor.py) para realizar las tareas de Batch:
nano batch_processor.py
CÃ³digo Python (batch_processor.py)


## Procesamiento Streaming

## Crea un nuevo archivo llamado producer.py 
nano producer.py 
CÃ³digo del Productor de Kafka (producer.py)

## Crea un nuevo archivo llamado stream_processor.py
nano stream_processor.py
CÃ³digo del Consumidor Spark Streaming (stream_processor.py)

## Abrir 5 terminales para iniciar los servicios y procesos:

| Terminal | AcciÃ³n | Comando |
|-----------|--------|---------|
| 1 | Iniciar Hadoop | start-all.sh |
| 2 | Iniciar ZooKeeper | cd ~/kafka_2.13-3.7.0 && bin/zookeeper-server-start.sh config/zookeeper.properties |
| 3 | Iniciar Kafka Broker | cd ~/kafka_2.13-3.7.0 && bin/kafka-server-start.sh config/server.properties |
| 4 | Productor Kafka | python3 producer.py |
| 5 | Spark Streaming | spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 stream_processor.py |

## ğŸ“š CrÃ©ditos

**Autor:** Keidys Vanegas  
**Fecha:** Octubre 2025
